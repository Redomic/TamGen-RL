Namespace(no_progress_bar=False, log_interval=1000, log_format=None, tensorboard_logdir='', tbmf_wrapper=False, seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='nag', lr_scheduler='fixed', task='translation_coord', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=1024, max_sentences=None, required_batch_size_multiple=8, dataset_impl=None, gen_subset='gen_8fln', num_shards=1, shard_id=0, path='checkpoints/crossdock_pdb_A10/checkpoint_best.pt', remove_bpe=None, quiet=False, model_overrides='{}', results_path=None, beam=20, nbest=20, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, prefix_string=None, tag_prefix_token=False, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, print_alignment=False, scorer='bleu', codegen_pov_replace_unk=True, dump_hyp=None, momentum=0.99, weight_decay=0.0, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='./TamGen_Demo_Data', source_lang='tg', target_lang='m1', lazy_load=False, raw_text=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, coord_mode='raw', use_src_coord=True, use_tgt_coord=False, shuffle_input=False, vae=False, sample_beta=1.0, hint=False, hint_rate=0.5, gen_coord_noise=False, gen_rot=False, gen_vae=True, remove_prefix_fragment=False)
| [tg] dictionary: 25 types
| [m1] dictionary: 962 types
| loading model(s) from checkpoints/crossdock_pdb_A10/checkpoint_best.pt
checkpoints/crossdock_pdb_A10/checkpoint_best.pt
Traceback (most recent call last):
  File "/workspace/workspace/TamGen/tester.py", line 13, in <module>
    worker = TamGenDemo(
  File "/workspace/workspace/TamGen/TamGen_OG.py", line 125, in __init__
    self.models, _model_args = checkpoint_utils.load_model_ensemble(
  File "/workspace/workspace/TamGen/fairseq/checkpoint_utils.py", line 160, in load_model_ensemble
    ensemble, args, _task = load_model_ensemble_and_task(filenames, arg_overrides, task)
  File "/workspace/workspace/TamGen/fairseq/checkpoint_utils.py", line 171, in load_model_ensemble_and_task
    state = load_checkpoint_to_cpu(filename, arg_overrides)
  File "/workspace/workspace/TamGen/fairseq/checkpoint_utils.py", line 140, in load_checkpoint_to_cpu
    state = torch.load(
  File "/root/miniconda3/envs/TamGen/lib/python3.9/site-packages/torch/serialization.py", line 1529, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL argparse.Namespace was not an allowed global by default. Please use `torch.serialization.add_safe_globals([argparse.Namespace])` or the `torch.serialization.safe_globals([argparse.Namespace])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
